---
title: "Bayes Network"
author: "Mike"
date: "2020/3/20"
output: ioslides_presentation
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Packages
```{r echo=TRUE, message=FALSE, warning=FALSE}

package_name = c('e1071', 'klaR', 'dplyr', 'DT', 'ggplot2', 'tidyr', 'deal')
for(p in package_name) {
  if(! p %in% rownames(installed.packages())){
    cat('Try to install ', p, 'now !\n')
    tryCatch({
      install.packages(p)
    }, error = function(e) {
      print(e)
      conditionMessage(e)
    })
  }else{
    cat(p, 'has been installed !\n')
  }
}

```

## Library
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(magrittr) # %<>%
library(dplyr) # Data Manipulation
library(tidyr) # gather and spread dataframe
library(e1071) # NaiveBayes
library(klaR) # NaiveBayes
library(DT) # Datatable
library(ggplot2) # Plot
library(deal) # Bayesian network


```


## Contingency Table

![](ContingencyTable.jpg){width=100%}

```{r}

model_performance <- function(pred_cond, true_cond){
  
  # Confusion Matrix, Contingency Table
  confusion_matrix <- table(pred_cond, true_cond)
  
  # Hit, True Positive
  TP <-  confusion_matrix[1,1]
  # Correct Rejection, True Negative
  TN <- confusion_matrix[2,2]
  # False Alarm, Type I Error, False Positive
  FP <-  confusion_matrix[1,2]
  # Miss, Type II Error, False Negative
  FN <-  confusion_matrix[2,1]
  
  
  
  # Sensitivity, Recall, True Positive Rate
  TPR <- TP / (TP + FN)
  
  # Specificity, Selectivity, True Negative Rate
  TNR <- TN / (TN + FP)
  
  # Precision, Positive Predictive Value
  PPV <- TP / (TP + FP)
  
  # Negative Prediction Value
  NPV <- TN / (TN + FN)
  
  # Miss Rate, False Negative Rate
  FNR <- FN /(FN + TP)
  
  # Fall Out, False Positive Rate
  FPR <-  FP / (FP + TN)
  
  # False Discovery Rate
  FDR <- FP / (FP + TP)
  
  # False Omission Rate
  FOR <- FN / (FN + TN)
  
  
  
  # Threat Score, Critical Success Index
  TS <- TP / (TP + FN + FP)
  
  # Accuracy
  ACC <- (TP + TN) / sum(confusion_matrix)
  
  # Balanced Accuracy, Harmonic Mean of Precision and Sensitivity
  BA <- (TPR + TNR) / 2
  
  # F1 Score
  F1 <- 2*(PPV*TPR)/(PPV+TPR)
  
  # Matthews correlation coefficient
  MCC <- (TP*TN -FP*FN) / (sqrt(TP+FP)*sqrt(TP+FN)*sqrt(TN+FP)*sqrt(TN+FN))
  
  # Bookmaker Informedness
  BM <- TPR + TNR - 1
  
  # Markedness, delta-P
  MK <- PPV + NPV - 1
  
  df = data.frame(
        TPR = TPR, 
        TNR = TNR, 
        PPV = PPV, 
        NPV = NPV, 
        FNR = FNR, 
        FPR = FPR, 
        FDR = FDR, 
        FOR = FOR, 
        TS = TS, 
        ACC = ACC, 
        BA = BA, 
        F1 = F1, 
        MCC = MCC, 
        BM = BM, 
        MK = MK
      )
  
  
  positive_measure = df[c('TPR', 'TNR', 'PPV', 'NPV', 'F1',
                          'ACC', 'TS', 'BA', "BM", 'MK')]%>% gather

  plot_positive <-  ggplot(positive_measure, 
       aes(x=reorder(key,-value),y=value,fill=key))+
        geom_bar(stat="identity")+
        # coord_polar(theta="x",direction=1)+
        labs(x="Measure",y="Performance")+
        theme(legend.position="bottom",legend.box="horizontal")+
        ggtitle(label = 'Positive Model Performance',
                subtitle = 'The higher, the better.')+
        geom_text(aes(x = reorder(key,-value),
                            y=value, 
                            label = round(value, 2)),
                  vjust = 1.2)
  
  
  negative_measure = df[c("FNR", "FPR", "FDR", "FOR")]%>% gather

  plot_negative <- ggplot(negative_measure, 
       aes(x=reorder(key,-value),y=value,fill=key))+
        geom_bar(stat="identity")+
        # coord_polar(theta="x",direction=1)+
        labs(x="Measure",y="Performance")+
        theme(legend.position="bottom",legend.box="horizontal")+
        ggtitle(label = 'Negative Model Performance',
                subtitle = 'The lower, the better.')+
        geom_text(aes(x = reorder(key,-value),
                            y=value, 
                            label = round(value, 2)),
                  vjust = 1.2)


  return(
    list(
      confusion_matrix = confusion_matrix,
      TP = TP, 
      TN = TN, 
      FP = FP, 
      FN = FN, 
      
      TPR = TPR, 
      TNR = TNR, 
      PPV = PPV, 
      NPV = NPV, 
      FNR = FNR, 
      FPR = FPR, 
      FDR = FDR, 
      FOR = FOR, 
      TS = TS, 
      ACC = ACC, 
      BA = BA, 
      F1 = F1, 
      MCC = MCC, 
      BM = BM, 
      MK = MK,
  
      df = df,
      plot_positive = plot_positive,
      plot_negative = plot_negative
    )
  )
  
}

```


  
[Reference : Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)





## Data I : Titanic

```{r cars, echo = TRUE}
data('Titanic') # Its class is table. 
df_Titanic = data.frame(Titanic)
datatable(df_Titanic, options = list(pageLength = 5))

```

## Questions

+ The factor of **Sirvived** is correlated with **Class**, **Sex**, or **Age** ?
  1. The survival probability is more in 1st class?
  2. The female survived more than the male?
  3. The children are prior to be rescued?
  
+ Are **Class**, **Sex**, and **Age** independent variables?


+ Is it possible to describe the relationship of these explanatory and explained variables?


## Raw data

```{r echo=TRUE}

repeating_sequence <- rep(1:nrow(df_Titanic), df_Titanic$Freq)
rawdata <- df_Titanic[repeating_sequence,]
rawdata$Freq <- NULL # delete Freq column

nrow(df_Titanic) # Titanic is an aggregation data
nrow(rawdata) 

```


## Bayes Theorem

+ Explainatory : Class(F1), Sex(F2), Age(F3)
+ Explained : Survived(C)

Target: find posterior prob. $P(C|F_1,F_2, F_3)$

Now we calculate these below with observed sample data :

1. $\hat P(F_1,F_2, F_3)$ ... sometimes we may get whole population data (evidence) 

2. $\hat P(F_1,F_2, F_3|C)$ 

3. $\hat P(C|F_1,F_2, F_3)$ 

4. $\hat P(C)$ : sometimes we may get more info about C, or let experts set a proper prior estimator


## Bayes Theorem

We have 2 ways to estimate$P(C|F_1,F_2, F_3)$

Plan A: Only use sample data to calc. $\hat P(C|F_1,F_2, F_3)$ 

Plan B: Use Bayesian concept $\frac{\hat P(C) Ã—\hat P(F_1,F_2, F_3|C)}{\hat P(F_1,F_2, F_3)}$


Since we dont have any prior Titanic survived info or experts's suggestion, only relying on the sample data, the plan A may differ **little** from plan B.



## Bayesian Model

+ Naive Bayes

  + Assuming the explanatory variables are **conditionally independent**.

  + [e1071::naiveBayes Source Code](https://rdrr.io/rforge/e1071/src/R/naiveBayes.R)

+ Bayesian Network

  The explanatory variables are **correlated**.






## Naive Bayes Model


```{r echo=TRUE}
# na.action: na.pass or na.omit 

model_NaiveBayes =  naiveBayes(formula = Survived ~ ., 
                               data = rawdata, 
                               na.action = na.pass)

pred_NaiveBayes <- predict(model_NaiveBayes,rawdata) # predict survived
Titanic_survived <- rawdata$Survived # real survived

perform_NaiveBayes = model_performance(pred_NaiveBayes, Titanic_survived)
perform_NaiveBayes$confusion_matrix

```


## NaiveBayes Performance

```{r}
perform_NaiveBayes$plot_positive
```



##  NaiveBayes Performance

```{r}
perform_NaiveBayes$plot_negative
```



## Bayesian Network (Custom Arrow)
```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
Titanic_network <- network(rawdata)
Titanic_prior = jointprior(Titanic_network)
Titanic_network %<>% {getnetwork(learn(. , rawdata, Titanic_prior))}

Titanic_network %<>% 
  {getnetwork(insert(. ,1, 4, rawdata, Titanic_prior))} %>% 
  {getnetwork(insert(. ,2, 4, rawdata, Titanic_prior))} %>% 
  {getnetwork(insert(. ,3, 4, rawdata, Titanic_prior))} %>% 
  {getnetwork(insert(. ,2, 1, rawdata, Titanic_prior))} %>% 
  {getnetwork(insert(. ,3, 1, rawdata, Titanic_prior))}


```

## Bayesian Network (Custom Arrow)

```{r}
plot(Titanic_network)
```



## Bayesian Network (Auto Search)

```{r echo=TRUE, message=FALSE, warning=FALSE}
Titanic_network <- network(rawdata)
Titanic_prior = jointprior(Titanic_network)

Titanic_network %<>% {getnetwork(learn(. , rawdata, Titanic_prior))}


```


## Bayesian Network (Auto Search)

```{r}
Titanic_autoNetwork <- autosearch(Titanic_network, rawdata, Titanic_prior, 
                                  trace = FALSE, removecycles = TRUE)

```

## Bayesian Network (Auto Search)

```{r}
plot(getnetwork(Titanic_autoNetwork))
```

